{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dog_app.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratyakshajha/project-dog-classification/blob/master/dog_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oA6s-5hWv2sR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "### The Road Ahead\n",
        "\n",
        "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
        "\n",
        "* [Step 0](#step0): Import Datasets\n",
        "* [Step 1](#step1): Detect Humans\n",
        "* [Step 2](#step2): Detect Dogs\n",
        "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
        "* [Step 4](#step4): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
        "* [Step 5](#step5): Write your Algorithm\n",
        "* [Step 6](#step6): Test Your Algorithm\n",
        "\n",
        "---\n",
        "<a id='step0'></a>\n",
        "## Step 0: Import Datasets\n",
        "\n",
        "Make sure that the required human and dog datasets are downloaded :\n",
        "* [Dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip). \n",
        "\n",
        "* [Human dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip).  \n",
        "\n",
        "*Note: for a Windows machine, use [7zip](http://www.7-zip.org/) to extract the folder.*\n",
        "\n",
        "In the code cells below, we download and unzip the required data files and, save the file paths for both the human (LFW) dataset and dog dataset in the numpy arrays `human_files` and `dog_files`."
      ]
    },
    {
      "metadata": {
        "id": "ns0T-eHkxk2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ebb87df-c2f7-409e-b525-4a9c9a2bb152"
      },
      "cell_type": "code",
      "source": [
        "# download the required data files\n",
        "\n",
        "!wget -cq https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
        "!wget -cq https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip\n",
        "!git clone https://github.com/pratyakshajha/project-dog-classification.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'project-dog-classification' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FnBDAm8K0fJm",
        "colab_type": "code",
        "outputId": "c65916cf-8bab-467d-bfaf-4cc305da7e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# unzip the data files\n",
        "\n",
        "!rm -r dogImages || true\n",
        "!unzip -qq dogImages.zip\n",
        "\n",
        "!rm -r lfw || true\n",
        "!unzip -qq lfw.zip\n",
        "\n",
        "!rm -r __MACOSX || true"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'dogImages': No such file or directory\n",
            "rm: cannot remove 'lfw': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X1rXsF2-YfnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# all imports\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2                \n",
        "import matplotlib.pyplot as plt \n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets\n",
        "\n",
        "%matplotlib inline                               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2toUJ8KPv2sU",
        "colab_type": "code",
        "outputId": "02ad3b36-8eea-4912-a126-035c941f9c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# load filenames for human and dog images\n",
        "human_files = np.array(glob(\"lfw/*/*\"))\n",
        "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print('There are %d total human images.' % len(human_files))\n",
        "print('There are %d total dog images.' % len(dog_files))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 13233 total human images.\n",
            "There are 8351 total dog images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dQoamwswv2sb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id='step1'></a>\n",
        "## Step 1: Detect Humans\n",
        "\n",
        "In this section, OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images is used.  \n",
        "\n",
        "OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.  In the next code cell, we can see how to use this detector to find human faces in a sample image."
      ]
    },
    {
      "metadata": {
        "id": "SCpiy6-0v2sc",
        "colab_type": "code",
        "outputId": "3adcbc28-a17d-4628-e7ef-e6c80dd1006f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "# extract pre-trained face detector\n",
        "face_cascade = cv2.CascadeClassifier('project-dog-classification/haarcascades/haarcascade_frontalface_alt.xml')\n",
        "\n",
        "# load color (BGR) image\n",
        "img = cv2.imread(human_files[0])\n",
        "# convert BGR image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# find faces in image\n",
        "faces = face_cascade.detectMultiScale(gray)\n",
        "\n",
        "# print number of faces detected in the image\n",
        "print('Number of faces detected:', len(faces))\n",
        "\n",
        "# get bounding box for each detected face\n",
        "for (x,y,w,h) in faces:\n",
        "    # add bounding box to color image\n",
        "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    \n",
        "# convert BGR image to RGB for plotting\n",
        "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# display the image, along with bounding box\n",
        "plt.imshow(cv_rgb)\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of faces detected: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlKUs5UhZKoilLGUpR8r/A101FkeJ7CIdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2aGg09YQv2sh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
        "\n",
        "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
        "\n",
        "### Write a Human Face Detector\n",
        "\n",
        "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
      ]
    },
    {
      "metadata": {
        "id": "cE_Cb0kDv2si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# returns \"True\" if face is detected in image stored at img_path\n",
        "def face_detector(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    return len(faces) > 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htYWf7kBv2sn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assessing the Human Face Detector\n",
        "\n",
        "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  Our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`."
      ]
    },
    {
      "metadata": {
        "id": "pLWB3M1pv2sq",
        "colab_type": "code",
        "outputId": "dd7a9aeb-17f5-4b3c-ba9f-284726f3f418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "human_files_short = human_files[:100]\n",
        "dog_files_short = dog_files[:100]\n",
        "\n",
        "count = []\n",
        "temp = 0\n",
        "for file in tqdm(human_files_short):\n",
        "  if face_detector(file):\n",
        "    temp += 1\n",
        "count.append(temp)    \n",
        "\n",
        "temp = 0\n",
        "for file in tqdm(dog_files_short):\n",
        "  if face_detector(file):\n",
        "    temp += 1\n",
        "count.append(temp)   \n",
        "    \n",
        "print('\\nPercentage of human face detected in the first 100 images:\\nhuman_files:{}\\tdog_files:{}'.format(count[0], count[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 22.03it/s]\n",
            "100%|██████████| 100/100 [00:25<00:00,  4.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Percentage of human face detected in the first 100 images:\n",
            "human_files:99\tdog_files:11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gNE7WTkov2s4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id='step2'></a>\n",
        "## Step 2: Detect Dogs\n",
        "\n",
        "In this section, we use a [pre-trained model](http://pytorch.org/docs/master/torchvision/models.html) to detect dogs in images.  \n",
        "\n",
        "### Obtain Pre-trained VGG-16 Model\n",
        "\n",
        "The code cell below downloads the VGG-16 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  "
      ]
    },
    {
      "metadata": {
        "id": "1q03vpysv2s5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91e8fc23-39f4-4292-99a5-cbba0b1bc06b"
      },
      "cell_type": "code",
      "source": [
        "# define VGG16 model\n",
        "VGG16 = models.vgg16(pretrained=True)\n",
        "\n",
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# move model to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    VGG16 = VGG16.cuda()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.torch/models/vgg16-397923af.pth\n",
            "553433881it [00:05, 94219838.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rhxA-shiv2s9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Given an image, this pre-trained VGG-16 model returns a prediction (derived from the 1000 possible categories in ImageNet) for the object that is contained in the image."
      ]
    },
    {
      "metadata": {
        "id": "dRRubqgHv2s-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Making Predictions with a Pre-trained Model\n",
        "\n",
        "In the next code cell, the function accepts a path to an image (such as `'dogImages/train/001.Affenpinscher/Affenpinscher_00001.jpg'`) as input and returns the index corresponding to the ImageNet class that is predicted by the pre-trained VGG-16 model.  The output should always be an integer between 0 and 999, inclusive."
      ]
    },
    {
      "metadata": {
        "id": "lF6tVv-UtCgI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    ''' \n",
        "    Scales, crops, and normalizes a PIL image for a PyTorch       \n",
        "    model, returns an Numpy array\n",
        "    '''\n",
        "    # Open the image\n",
        "    from PIL import Image\n",
        "    img = Image.open(image)\n",
        "    # Resize\n",
        "    if img.size[0] > img.size[1]:\n",
        "        img.thumbnail((10000, 256))\n",
        "    else:\n",
        "        img.thumbnail((256, 10000))\n",
        "    # Crop \n",
        "    left_margin = (img.width-224)/2\n",
        "    bottom_margin = (img.height-224)/2\n",
        "    right_margin = left_margin + 224\n",
        "    top_margin = bottom_margin + 224\n",
        "    img = img.crop((left_margin, bottom_margin, right_margin,   \n",
        "                      top_margin))\n",
        "    # Normalize\n",
        "    img = np.array(img)/255\n",
        "    mean = np.array([0.485, 0.456, 0.406]) \n",
        "    std = np.array([0.229, 0.224, 0.225]) \n",
        "    img = (img - mean)/std\n",
        "    \n",
        "    # Move color channels to first dimension as expected by PyTorch\n",
        "    img = img.transpose((2, 0, 1))    \n",
        "    \n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4H-l2OC6v2s_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set PIL to be tolerant of image files that are truncated.\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def VGG16_predict(img_path):\n",
        "    '''\n",
        "    Use pre-trained VGG-16 model to obtain index corresponding to \n",
        "    predicted ImageNet class for image at specified path\n",
        "    \n",
        "    Args:\n",
        "        img_path: path to an image\n",
        "        \n",
        "    Returns:\n",
        "        Index corresponding to VGG-16 model's prediction\n",
        "    '''    \n",
        "    ## Load and pre-process an image from the given img_path\n",
        "    ## Return the *index* of the predicted class for that image\n",
        "    \n",
        "    # Process image\n",
        "    img = process_image(img_path) \n",
        "    img = torch.from_numpy(img).type(torch.FloatTensor) \n",
        "    img.unsqueeze_(0)\n",
        "    img = img.cuda()\n",
        "\n",
        "    # Predict top label\n",
        "    probs = torch.exp(VGG16.forward(img)) \n",
        "    top_prob, top_lab = probs.topk(1)     \n",
        "    \n",
        "    return top_lab # predicted class index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrBzeq_uv2tC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Writing a Dog Detector\n",
        "\n",
        "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained VGG-16 model, we need only check if the pre-trained model predicts an index between 151 and 268 (inclusive).\n",
        "\n",
        "Use these ideas the `dog_detector` function below returns `True` if a dog is detected in an image (and `False` if not)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "62dce58d-ce93-4af0-ebf3-2ff686ba1f33",
        "id": "fPyrXqrIx8Tk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "int(VGG16_predict('dogImages/train/001.Affenpinscher/Affenpinscher_00001.jpg'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0XkXttCzv2tD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### returns \"True\" if a dog is detected in the image stored at img_path\n",
        "def dog_detector(img_path):\n",
        "    pred = int(VGG16_predict(img_path))\n",
        "    if 150 < pred <269:\n",
        "      return True\n",
        "    else:    \n",
        "      return False "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiJ9f9E8v2tE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assessing the Dog Detector"
      ]
    },
    {
      "metadata": {
        "id": "uXk5D382v2tH",
        "colab_type": "code",
        "outputId": "c9900485-88ba-4b96-f5a9-7fa8627e7e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "### Test the performance of the dog_detector function\n",
        "### on the images in human_files_short and dog_files_short.\n",
        "human_files_short = human_files[:100]\n",
        "dog_files_short = dog_files[:100]\n",
        "\n",
        "count = []\n",
        "temp = 0\n",
        "for file in tqdm(human_files_short):\n",
        "  if dog_detector(file):\n",
        "    temp += 1\n",
        "count.append(temp)    \n",
        "\n",
        "temp = 0\n",
        "for file in tqdm(dog_files_short):\n",
        "  if dog_detector(file):\n",
        "    temp += 1\n",
        "count.append(temp)   \n",
        "    \n",
        "print('\\nPercentage of dogs detected in the first 100 images:\\nhuman_files:{}\\tdog_files:{}'.format(count[0], count[1]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 30.09it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Percentage of dogs detected in the first 100 images:\n",
            "human_files:0\tdog_files:99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "58OlsveIv2tO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id='step3'></a>\n",
        "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
        "\n",
        "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, I create a CNN that classifies dog breeds and try to attain a test accuracy of at least 10%. \n",
        "\n",
        "The task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have trouble distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
        "\n",
        "Brittany | Welsh Springer Spaniel\n",
        "- | - \n",
        "<img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Brittany_02625.jpg?raw=1\" width=\"100\"> | <img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Welsh_springer_spaniel_08203.jpg?raw=1\" width=\"200\">\n",
        "\n",
        "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
        "\n",
        "Curly-Coated Retriever | American Water Spaniel\n",
        "- | -\n",
        "<img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Curly-coated_retriever_03896.jpg?raw=1\" width=\"200\"> | <img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/American_water_spaniel_00648.jpg?raw=1\" width=\"200\">\n",
        "\n",
        "\n",
        "Likewise, recall that labradors come in yellow, chocolate, and black. The vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
        "\n",
        "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
        "- | -\n",
        "<img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Labrador_retriever_06457.jpg?raw=1\" width=\"150\"> | <img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Labrador_retriever_06455.jpg?raw=1\" width=\"240\"> | <img src=\"https://github.com/pratyakshajha/deep-learning-v2-pytorch/blob/master/project-dog-classification/images/Labrador_retriever_06449.jpg?raw=1\" width=\"220\">\n",
        "\n",
        "The random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  "
      ]
    },
    {
      "metadata": {
        "id": "6EYXtmsGaPit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Specify Data Loaders for the Dog Dataset\n",
        "\n",
        "For preprocessing the data, several functions from `torch.transforms` module are used. The images are cropped and normalised according to imagenet dataset. This is necessary as the pre-trained models need input images to be of same dimensions and similar distribution as the images it was trained on.  The images were resized to be 224 by 224 pixels. Mean and standard deviation of `[0.485, 0.456, 0.406]` and `[0.229, 0.224, 0.225]` are applied.\n",
        "\n",
        "The training data is also augmented, while the validation and testing data is only adjusted according to imagenet data. The augmentation that is added is of the form:\n",
        "\n",
        "\n",
        "*   Rotation\n",
        "*   Horizontally and Vertically flipped\n",
        "*   Variation in brightness, contrast and saturation"
      ]
    },
    {
      "metadata": {
        "id": "ap2vyzAJv2tO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Write data loaders for training, validation, and test sets\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "# Transforms for the training and validation sets\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([        \n",
        "        transforms.ColorJitter(brightness=.2, contrast=.2, saturation=.2),\n",
        "        transforms.RandomRotation(45),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_6Wrf__zEmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dirs = {'train': 'dogImages/train', \n",
        "        'valid': 'dogImages/valid',\n",
        "        'test': 'dogImages/test'}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(dirs[x],   transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "loaders_scratch = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64, shuffle=True) for x in ['train', 'valid', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) \n",
        "                              for x in ['train', 'valid', 'test']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6Kpm-h9v2tU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Architecture\n",
        "\n",
        "Create a CNN to classify dog breed. I tried to replicate a smaller architecture similar to VGG model's architecture. The A configuration is used here. As the the depth of this configuration was too large for my colaboratory notebook to handle, I reduced the number of convolution filters in each layer. \n",
        "\n",
        "*VGG architecture:*\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/0*HREIJ1hjF7z4y9Dd.jpg\" width=\"400\">\n",
        "\n",
        "\n",
        "*My architecture*\n",
        "\n",
        "\n",
        "| Input Image        |\n",
        "|-----------------------|\n",
        "| (3x3) Convolutions - 16 |\n",
        "| Relu Activation     |\n",
        "| (2x2) Max Pooling     |\n",
        "| (3x3) Convolutions  - 16|\n",
        "| Relu Activation     |\n",
        "| (2x2) Max Pooling     |\n",
        "| (3x3) Convolutions - 32 |\n",
        "| Relu Activation     |\n",
        "| (2x2) Max Pooling     |\n",
        "| (3x3) Convolutions - 64|\n",
        "| Relu Activation     |\n",
        "| (2x2) Max Pooling     |\n",
        "| FC layer 1 - 4096  |\n",
        "| FC layer 2  - 4096 |\n",
        "| FC Layer 3  - 133  |\n",
        "| Softmax  |\n",
        "\n",
        "- Each convolution layer has filter size = (3x3), stride = (1x1) and padding = (1x1). The resulting tensors are of same size as that of input tensors. Multiple (3x3) convolution filters in a sequence work as higher order filters. At later layers, they help to indentify higher level features.\n",
        "- Each convolution layer is followed by Relu activation. This adds non-linearity and helps in speeding up training.\n",
        "- Relu activation is followed by Max Pool layer with kernel size = 2, stride = 2 and zero padding. This reduces the size of tensor by half. \n",
        "- Three fully connected layers are added for final classification along with dropout. Dropout adds some regularization in the network. \n",
        "- While training, Cross entropy loss is used. As this is a classification task, cross entropy works well as it fits according to the probability distribution of the data. Adam opimizer gives one of the best results as compared to other optimizers. Learning rate schedular is also added.  "
      ]
    },
    {
      "metadata": {
        "id": "ut7qPb_mv2tW",
        "colab_type": "code",
        "outputId": "d110d3b6-1273-402e-9d78-7623cb1c4447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    ### choose an architecture, and complete the class\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        ## Define layers of a CNN\n",
        "        # convolutional layer (sees 224x224x3 image tensor)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 112x112x112 tensor)\n",
        "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "        # convolutional layer (sees 56x56x56 tensor)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 28x28x28 tensor)\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # linear layer (512 * 14 * 14 -> 4096)\n",
        "        self.fc1 = nn.Linear(64*14*14, 4096)\n",
        "        # linear layer (4096 -> 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        # linear layer (4096 -> number of classes)\n",
        "        self.fc3 = nn.Linear(4096, len(class_names))\n",
        "        # dropout layer (p=0.5)\n",
        "        self.dropout = nn.Dropout(0.5)        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        ## Define forward behavior\n",
        "        # add sequence of convolutional and max pooling layers        \n",
        "        x = self.pool(F.relu(self.conv1(x)))       \n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        # flatten image input, size is depth of image in previous maxpool*depth of convolution\n",
        "        x = x.view(-1, 64*14*14)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# instantiate the CNN\n",
        "model_scratch = Net()\n",
        "print(model_scratch)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if use_cuda:\n",
        "    model_scratch.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=12544, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=133, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AP5QPrvjv2tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Specify Loss Function and Optimizer\n",
        "\n",
        "Use the next code cell to specifies a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  Save the chosen loss function as `criterion_scratch`, and the optimizer as `optimizer_scratch` below.\n"
      ]
    },
    {
      "metadata": {
        "id": "7Gp-OcGGv2tj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### select loss function\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "\n",
        "### select optimizer\n",
        "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 4 epochs\n",
        "scheduler_scratch = lr_scheduler.StepLR(optimizer_scratch, step_size = 8, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7wY_21mv2tl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and Validate the Model\n",
        "\n",
        "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_scratch.pt'`."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w2ifvK9EdG1w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_losses = {'epoch': [],\n",
        "              'train': [],\n",
        "              'valid': [],\n",
        "              'test': []\n",
        "             }\n",
        "\n",
        "all_accuracies = {'epoch': [],\n",
        "                  'train': [],\n",
        "                  'valid': [],\n",
        "                  'test': []\n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I3PkoO9HdG1z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_current_time():\n",
        "  # Display time in IST(UTC+5:30)\n",
        "  hours, mins, secs = str(datetime.datetime.now().time())[:-8].split(':')\n",
        "  hours, mins, secs = int(hours), int(mins), int(secs)\n",
        "\n",
        "  if (mins+30)<60:\n",
        "    hours = hours+5 \n",
        "    mins=mins+30 \n",
        "  else:\n",
        "    hours = hours+6 \n",
        "    mins = (mins+30) - 60\n",
        "    \n",
        "  print('Current time - {}:{}:{}'.format(hours, mins, secs)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNNiYSCMv2tm",
        "colab_type": "code",
        "outputId": "c86c8844-7f2f-4707-d4d0-2bad9059e61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2278
        }
      },
      "cell_type": "code",
      "source": [
        "# the following import is required for training to be robust to truncated images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    print_current_time()       \n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        all_losses['epoch'].append(epoch)\n",
        "        all_accuracies['epoch'].append(epoch)\n",
        "        start_time = time.time()\n",
        "        print('-'*11)\n",
        "        print('Epoch: {}'.format(epoch))\n",
        "       \n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_running_corrects = 0\n",
        "        valid_running_corrects = 0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders_scratch['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "                                \n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer_scratch.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            outputs = model_scratch(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion_scratch(outputs, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer_scratch.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "            train_running_corrects += torch.sum(preds == target.data)   \n",
        "            \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders_scratch['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            outputs = model_scratch(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion_scratch(outputs, target)\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "            valid_running_corrects += torch.sum(preds == target.data)\n",
        "            \n",
        "        # calculate average losses and accuracies\n",
        "        train_loss = train_loss/len(loaders_scratch['train'].dataset)\n",
        "        all_losses['train'].append(train_loss)\n",
        "        valid_loss = valid_loss/len(loaders_scratch['valid'].dataset)\n",
        "        all_losses['valid'].append(valid_loss)\n",
        "\n",
        "        train_acc = train_running_corrects.double()/len(loaders_scratch['train'].dataset)\n",
        "        all_accuracies['train'].append(train_acc)\n",
        "        valid_acc = valid_running_corrects.double()/len(loaders_scratch['valid'].dataset)\n",
        "        all_accuracies['valid'].append(valid_acc)\n",
        "        time_epoch = time.time() - start_time\n",
        "\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Training Loss: {:.6f} \\tValidation Loss: {:.6f}\\tTime: {:.0f}m {:.0f}s'.format(             \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            time_epoch // 60, time_epoch % 60\n",
        "            ))\n",
        "        \n",
        "        ## save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "          print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "          valid_loss_min,\n",
        "          valid_loss))\n",
        "          torch.save(model_scratch.state_dict(), 'model_scratch.pt')\n",
        "          valid_loss_min = valid_loss  \n",
        "          \n",
        "        # every 5 epochs print current time\n",
        "        if epoch%5 == 0:\n",
        "          print('*'*11)\n",
        "          print_current_time()\n",
        "          print('*'*11)          \n",
        "        \n",
        "    print()\n",
        "            \n",
        "    # return trained model\n",
        "    return model\n",
        "\n",
        "\n",
        "# train the model\n",
        "model_scratch = train(30, loaders_scratch, model_scratch, optimizer_scratch, \n",
        "                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current time - 18:56:3\n",
            "-----------\n",
            "Epoch: 1\n",
            "Training Loss: 4.882817 \tValidation Loss: 4.863901\tTime: 4m 52s\n",
            "Validation loss decreased (inf --> 4.863901).  Saving model ...\n",
            "-----------\n",
            "Epoch: 2\n",
            "Training Loss: 4.863441 \tValidation Loss: 4.821417\tTime: 4m 50s\n",
            "Validation loss decreased (4.863901 --> 4.821417).  Saving model ...\n",
            "-----------\n",
            "Epoch: 3\n",
            "Training Loss: 4.748388 \tValidation Loss: 4.590000\tTime: 4m 47s\n",
            "Validation loss decreased (4.821417 --> 4.590000).  Saving model ...\n",
            "-----------\n",
            "Epoch: 4\n",
            "Training Loss: 4.621376 \tValidation Loss: 4.493894\tTime: 4m 47s\n",
            "Validation loss decreased (4.590000 --> 4.493894).  Saving model ...\n",
            "-----------\n",
            "Epoch: 5\n",
            "Training Loss: 4.573231 \tValidation Loss: 4.434343\tTime: 4m 49s\n",
            "Validation loss decreased (4.493894 --> 4.434343).  Saving model ...\n",
            "***********\n",
            "Current time - 19:20:4\n",
            "***********\n",
            "-----------\n",
            "Epoch: 6\n",
            "Training Loss: 4.542214 \tValidation Loss: 4.417711\tTime: 4m 51s\n",
            "Validation loss decreased (4.434343 --> 4.417711).  Saving model ...\n",
            "-----------\n",
            "Epoch: 7\n",
            "Training Loss: 4.510779 \tValidation Loss: 4.363046\tTime: 4m 49s\n",
            "Validation loss decreased (4.417711 --> 4.363046).  Saving model ...\n",
            "-----------\n",
            "Epoch: 8\n",
            "Training Loss: 4.471723 \tValidation Loss: 4.327876\tTime: 4m 50s\n",
            "Validation loss decreased (4.363046 --> 4.327876).  Saving model ...\n",
            "-----------\n",
            "Epoch: 9\n",
            "Training Loss: 4.437939 \tValidation Loss: 4.282205\tTime: 4m 53s\n",
            "Validation loss decreased (4.327876 --> 4.282205).  Saving model ...\n",
            "-----------\n",
            "Epoch: 10\n",
            "Training Loss: 4.410265 \tValidation Loss: 4.283925\tTime: 4m 47s\n",
            "***********\n",
            "Current time - 19:45:0\n",
            "***********\n",
            "-----------\n",
            "Epoch: 11\n",
            "Training Loss: 4.374890 \tValidation Loss: 4.208352\tTime: 4m 48s\n",
            "Validation loss decreased (4.282205 --> 4.208352).  Saving model ...\n",
            "-----------\n",
            "Epoch: 12\n",
            "Training Loss: 4.352095 \tValidation Loss: 4.176968\tTime: 4m 49s\n",
            "Validation loss decreased (4.208352 --> 4.176968).  Saving model ...\n",
            "-----------\n",
            "Epoch: 13\n",
            "Training Loss: 4.331487 \tValidation Loss: 4.180449\tTime: 4m 52s\n",
            "-----------\n",
            "Epoch: 14\n",
            "Training Loss: 4.281216 \tValidation Loss: 4.115205\tTime: 4m 52s\n",
            "Validation loss decreased (4.176968 --> 4.115205).  Saving model ...\n",
            "-----------\n",
            "Epoch: 15\n",
            "Training Loss: 4.284041 \tValidation Loss: 4.099101\tTime: 4m 53s\n",
            "Validation loss decreased (4.115205 --> 4.099101).  Saving model ...\n",
            "***********\n",
            "Current time - 20:9:1\n",
            "***********\n",
            "-----------\n",
            "Epoch: 16\n",
            "Training Loss: 4.251091 \tValidation Loss: 4.111871\tTime: 4m 52s\n",
            "-----------\n",
            "Epoch: 17\n",
            "Training Loss: 4.223094 \tValidation Loss: 4.064979\tTime: 4m 57s\n",
            "Validation loss decreased (4.099101 --> 4.064979).  Saving model ...\n",
            "-----------\n",
            "Epoch: 18\n",
            "Training Loss: 4.204800 \tValidation Loss: 4.030948\tTime: 4m 55s\n",
            "Validation loss decreased (4.064979 --> 4.030948).  Saving model ...\n",
            "-----------\n",
            "Epoch: 19\n",
            "Training Loss: 4.208805 \tValidation Loss: 4.033294\tTime: 4m 52s\n",
            "-----------\n",
            "Epoch: 20\n",
            "Training Loss: 4.177284 \tValidation Loss: 4.023796\tTime: 4m 51s\n",
            "Validation loss decreased (4.030948 --> 4.023796).  Saving model ...\n",
            "***********\n",
            "Current time - 20:33:4\n",
            "***********\n",
            "-----------\n",
            "Epoch: 21\n",
            "Training Loss: 4.171363 \tValidation Loss: 4.012563\tTime: 4m 51s\n",
            "Validation loss decreased (4.023796 --> 4.012563).  Saving model ...\n",
            "-----------\n",
            "Epoch: 22\n",
            "Training Loss: 4.145225 \tValidation Loss: 3.993725\tTime: 4m 51s\n",
            "Validation loss decreased (4.012563 --> 3.993725).  Saving model ...\n",
            "-----------\n",
            "Epoch: 23\n",
            "Training Loss: 4.125598 \tValidation Loss: 3.945463\tTime: 4m 49s\n",
            "Validation loss decreased (3.993725 --> 3.945463).  Saving model ...\n",
            "-----------\n",
            "Epoch: 24\n",
            "Training Loss: 4.103309 \tValidation Loss: 4.028169\tTime: 4m 50s\n",
            "-----------\n",
            "Epoch: 25\n",
            "Training Loss: 4.096198 \tValidation Loss: 3.932953\tTime: 4m 49s\n",
            "Validation loss decreased (3.945463 --> 3.932953).  Saving model ...\n",
            "***********\n",
            "Current time - 20:57:5\n",
            "***********\n",
            "-----------\n",
            "Epoch: 26\n",
            "Training Loss: 4.078535 \tValidation Loss: 3.894303\tTime: 4m 51s\n",
            "Validation loss decreased (3.932953 --> 3.894303).  Saving model ...\n",
            "-----------\n",
            "Epoch: 27\n",
            "Training Loss: 4.037331 \tValidation Loss: 3.915383\tTime: 4m 52s\n",
            "-----------\n",
            "Epoch: 28\n",
            "Training Loss: 4.019847 \tValidation Loss: 3.869978\tTime: 4m 55s\n",
            "Validation loss decreased (3.894303 --> 3.869978).  Saving model ...\n",
            "-----------\n",
            "Epoch: 29\n",
            "Training Loss: 4.036162 \tValidation Loss: 3.882253\tTime: 4m 48s\n",
            "-----------\n",
            "Epoch: 30\n",
            "Training Loss: 3.993919 \tValidation Loss: 3.849650\tTime: 4m 51s\n",
            "Validation loss decreased (3.869978 --> 3.849650).  Saving model ...\n",
            "***********\n",
            "Current time - 21:22:1\n",
            "***********\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8PDOmStv2to",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the Model\n",
        "\n",
        "Try out your model on the test dataset of dog images. "
      ]
    },
    {
      "metadata": {
        "id": "J1YK5Oq-v2tp",
        "colab_type": "code",
        "outputId": "ed57039a-11e9-45bb-c75c-69cd8b8bddaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 3.832080\n",
            "\n",
            "\n",
            "Test Accuracy: 11% (93/836)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ky2qeIy-v2ts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id='step4'></a>\n",
        "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
        "\n",
        "Using transfer learning to create a CNN that can identify dog breed from images.  \n",
        "\n",
        "### Specify Data Loaders for the Dog Dataset\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rukUbszNz6D7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Write data loaders for training, validation, and test sets\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "# Transforms for the training and validation sets\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([        \n",
        "        transforms.ColorJitter(brightness=.2, contrast=.2, saturation=.2),\n",
        "        transforms.RandomRotation(45),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IrTtB-irz6D-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dirs = {'train': 'dogImages/train', \n",
        "        'valid': 'dogImages/valid',\n",
        "        'test': 'dogImages/test'}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(dirs[x],   transform=data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64, shuffle=True) for x in ['train', 'valid', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) \n",
        "                              for x in ['train', 'valid', 'test']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqkjOziwv2tu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Architecture\n",
        "\n",
        "Use transfer learning to create a CNN to classify dog breed. "
      ]
    },
    {
      "metadata": {
        "id": "2gpmr01sv2t0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Densenet model is used as the pretrained model here because:\n",
        "\n",
        "\n",
        "*   It has good performance on imagenet, only after Inception model. \n",
        "*   It uses a lot less number of parameters.\n",
        "*   It trains faster.\n",
        "*   The size of model created is not very large. (~160Mb) This will help when the model is finally deployed on a server for the app. \n",
        "*    Similar accuracy can be achieved with densenet121 model, which has lesser layers. The size for this one is around 30Mb.\n",
        "\n",
        "The classifier layers of the model is replaced by two fully connected layers. The first one has Relu activation while second is connected to log of softmax as output layer. \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VnNYVo6Uv2tv",
        "colab_type": "code",
        "outputId": "66a27609-9f3f-4f18-ce19-a1cb822ee666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "## Specify model architecture \n",
        "# Load the pretrained model from pytorch\n",
        "model_transfer = models.densenet161(pretrained=True)\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()\n",
        "    \n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(model_transfer.classifier.in_features, model_transfer.classifier.out_features)),\n",
        "                          ('relu', nn.ReLU()),                          \n",
        "                          ('fc2', nn.Linear(model_transfer.classifier.out_features, len(class_names))),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))  \n",
        "\n",
        "# Freeze training for all \"features\" layers\n",
        "for param in model_transfer.features.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "model_transfer.classifier = classifier"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.torch/models/densenet161-8d451a50.pth\n",
            "115730790it [00:01, 90054928.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iODB8cfDv2t0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Specify Loss Function and Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "Q5b-hiLvv2t3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.Adam(model_transfer.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 4 epochs\n",
        "scheduler_transfer = lr_scheduler.StepLR(optimizer_transfer, step_size = 3, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVWvrplev2t5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and Validate the Model\n",
        "\n",
        "Train and validate model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
      ]
    },
    {
      "metadata": {
        "id": "vcvNH0f01hBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_losses = {'epoch': [],\n",
        "              'train': [],\n",
        "              'valid': [],\n",
        "              'test': []\n",
        "             }\n",
        "\n",
        "all_accuracies = {'epoch': [],\n",
        "                  'train': [],\n",
        "                  'valid': [],\n",
        "                  'test': []\n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vhd_HesF2vUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_current_time():\n",
        "  \n",
        "  hours, mins, secs = str(datetime.datetime.now().time())[:-8].split(':')\n",
        "  hours, mins, secs = int(hours), int(mins), int(secs)\n",
        "\n",
        "  if (mins+30)<60:\n",
        "    hours = hours+5 \n",
        "    mins=mins+30 \n",
        "  else:\n",
        "    hours = hours+6 \n",
        "    mins = (mins+30) - 60\n",
        "    \n",
        "  if hours>24:\n",
        "    hours = hours - 24\n",
        "    \n",
        "  print('Current time - {}:{}:{}'.format(hours, mins, secs)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "toZcS8W6123M",
        "colab_type": "code",
        "outputId": "0c928fb3-7ccf-4885-f9da-3832e8ae6a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1343
        }
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "# number of epochs to train the model\n",
        "n_epochs = 10\n",
        "\n",
        "model_transfer.cuda()\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "print_current_time()\n",
        "\n",
        "for epoch in range(1, n_epochs+1):    \n",
        "    all_losses['epoch'].append(epoch)\n",
        "    all_accuracies['epoch'].append(epoch)\n",
        "    start_time = time.time()\n",
        "    print('-'*11)\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_running_corrects = 0\n",
        "    valid_running_corrects = 0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model_transfer.train()\n",
        "    for inputs, target in dataloaders['train']:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer_transfer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model_transfer(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion_transfer(outputs, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer_transfer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*inputs.size(0)\n",
        "        train_running_corrects += torch.sum(preds == target.data)        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model_transfer.eval()\n",
        "    for inputs, target in dataloaders['valid']:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model_transfer(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion_transfer(outputs, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*inputs.size(0)\n",
        "        valid_running_corrects += torch.sum(preds == target.data)\n",
        "    \n",
        "    # calculate average losses and accuracies\n",
        "    train_loss = train_loss/len(dataloaders['train'].dataset)\n",
        "    all_losses['train'].append(train_loss)\n",
        "    valid_loss = valid_loss/len(dataloaders['valid'].dataset)\n",
        "    all_losses['valid'].append(valid_loss)\n",
        "    \n",
        "    train_acc = train_running_corrects.double()/len(dataloaders['train'].dataset)\n",
        "    all_accuracies['train'].append(train_acc)\n",
        "    valid_acc = valid_running_corrects.double()/len(dataloaders['valid'].dataset)\n",
        "    all_accuracies['valid'].append(valid_acc)\n",
        "    time_epoch = time.time() - start_time\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Training Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        train_loss, valid_loss))\n",
        "    print('Training Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
        "        train_acc, valid_acc))\n",
        "    print_current_time()\n",
        "    print('Epoch Time: {:.0f}m {:.0f}s'.format(\n",
        "              time_epoch // 60, time_epoch % 60))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model_transfer.state_dict(), 'model_transfer.pth')\n",
        "        valid_loss_min = valid_loss       \n",
        "        \n",
        "    print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current time - 21:29:5\n",
            "-----------\n",
            "Epoch: 1\n",
            "Training Loss: 3.382925 \tValidation Loss: 1.389189\n",
            "Training Accuracy: 0.253743 \tValidation Accuracy: 0.674251\n",
            "Current time - 21:36:3\n",
            "Epoch Time: 6m 42s\n",
            "Validation loss decreased (inf --> 1.389189).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 2\n",
            "Training Loss: 1.773951 \tValidation Loss: 0.836884\n",
            "Training Accuracy: 0.528144 \tValidation Accuracy: 0.755689\n",
            "Current time - 21:43:2\n",
            "Epoch Time: 6m 43s\n",
            "Validation loss decreased (1.389189 --> 0.836884).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 3\n",
            "Training Loss: 1.513161 \tValidation Loss: 0.684952\n",
            "Training Accuracy: 0.574251 \tValidation Accuracy: 0.785629\n",
            "Current time - 21:50:0\n",
            "Epoch Time: 6m 43s\n",
            "Validation loss decreased (0.836884 --> 0.684952).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 4\n",
            "Training Loss: 1.387236 \tValidation Loss: 0.623844\n",
            "Training Accuracy: 0.610928 \tValidation Accuracy: 0.811976\n",
            "Current time - 21:56:4\n",
            "Epoch Time: 6m 42s\n",
            "Validation loss decreased (0.684952 --> 0.623844).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 5\n",
            "Training Loss: 1.281673 \tValidation Loss: 0.522412\n",
            "Training Accuracy: 0.638174 \tValidation Accuracy: 0.847904\n",
            "Current time - 22:3:2\n",
            "Epoch Time: 6m 43s\n",
            "Validation loss decreased (0.623844 --> 0.522412).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 6\n",
            "Training Loss: 1.230714 \tValidation Loss: 0.550459\n",
            "Training Accuracy: 0.642665 \tValidation Accuracy: 0.827545\n",
            "Current time - 22:10:1\n",
            "Epoch Time: 6m 41s\n",
            "\n",
            "-----------\n",
            "Epoch: 7\n",
            "Training Loss: 1.180172 \tValidation Loss: 0.478989\n",
            "Training Accuracy: 0.661976 \tValidation Accuracy: 0.851497\n",
            "Current time - 22:16:5\n",
            "Epoch Time: 6m 42s\n",
            "Validation loss decreased (0.522412 --> 0.478989).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 8\n",
            "Training Loss: 1.143221 \tValidation Loss: 0.490225\n",
            "Training Accuracy: 0.670659 \tValidation Accuracy: 0.858683\n",
            "Current time - 22:23:3\n",
            "Epoch Time: 6m 43s\n",
            "\n",
            "-----------\n",
            "Epoch: 9\n",
            "Training Loss: 1.097777 \tValidation Loss: 0.453316\n",
            "Training Accuracy: 0.685030 \tValidation Accuracy: 0.855090\n",
            "Current time - 22:30:1\n",
            "Epoch Time: 6m 43s\n",
            "Validation loss decreased (0.478989 --> 0.453316).  Saving model ...\n",
            "\n",
            "-----------\n",
            "Epoch: 10\n",
            "Training Loss: 1.075951 \tValidation Loss: 0.473887\n",
            "Training Accuracy: 0.694162 \tValidation Accuracy: 0.847904\n",
            "Current time - 22:37:0\n",
            "Epoch Time: 6m 43s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v9VfJFih1uLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODV5DskHv2t8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the Model"
      ]
    },
    {
      "metadata": {
        "id": "FIO7lEKjv2t9",
        "colab_type": "code",
        "outputId": "ef60b437-cba2-470f-9d36-4ded7a3be9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "\n",
        "print_current_time()\n",
        "# keep track of training and validation loss\n",
        "test_loss = 0.0\n",
        "test_running_corrects = 0\n",
        "\n",
        "######################    \n",
        "# test the model #\n",
        "######################\n",
        "model_transfer.eval()\n",
        "for inputs, target in dataloaders['test']:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    inputs, target = inputs.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    outputs = model_transfer(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion_transfer(outputs, target)\n",
        "    # update average validation loss \n",
        "    test_loss += loss.item()*inputs.size(0)\n",
        "    test_running_corrects += torch.sum(preds == target.data)\n",
        "\n",
        "# calculate average loss and accuracy\n",
        "test_loss = test_loss/len(dataloaders['test'].dataset)\n",
        "all_losses['test'].append(test_loss)\n",
        "\n",
        "test_acc = test_running_corrects.double()/len(dataloaders['test'].dataset)\n",
        "all_accuracies['test'].append(test_acc)\n",
        "time_epoch = time.time() - start_time\n",
        "\n",
        "# print training/validation statistics \n",
        "print('Test Loss: {:.6f}'.format(test_loss))\n",
        "print('Test Accuracy: {:.6f}'.format(test_acc*100))\n",
        "print_current_time()\n",
        "print('Epoch Time: {:.0f}m {:.0f}s'.format(\n",
        "          time_epoch // 60, time_epoch % 60))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current time - 22:37:0\n",
            "Test Loss: 0.498555\n",
            "Test Accuracy: 83.014354\n",
            "Current time - 22:37:3\n",
            "Epoch Time: 7m 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TCacKl8iv2uC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predicting Dog Breed with the Model"
      ]
    },
    {
      "metadata": {
        "id": "x0F_osUHv2uD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Write a function that takes a path to an image as input\n",
        "### and returns the dog breed that is predicted by the model.\n",
        "\n",
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "class_names = [item[4:].replace(\"_\", \" \") for item in class_names]\n",
        "\n",
        "def predict_breed_transfer(img_path):\n",
        "    # load the image and return the predicted breed\n",
        "    # Process image\n",
        "    img = process_image(img_path) \n",
        "    img = torch.from_numpy(img).type(torch.FloatTensor) \n",
        "    img.unsqueeze_(0)\n",
        "    img = img.cuda()\n",
        "\n",
        "    # Predict top label\n",
        "    probs = torch.exp(model_transfer.forward(img)) \n",
        "    top_prob, top_lab = probs.topk(1)     \n",
        "    return class_names[int(top_lab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjboU4VLv2uG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id='step5'></a>\n",
        "## Step 5: Writing the Algorithm\n",
        "\n",
        "The algorithm accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
        "- if a __dog__ is detected in the image, return the predicted breed.\n",
        "- if a __human__ is detected in the image, return the resembling dog breed.\n",
        "- if __neither__ is detected in the image, provide output that indicates an error."
      ]
    },
    {
      "metadata": {
        "id": "3Tgd9Qnfv2uG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Write your algorithm.\n",
        "### Feel free to use as many code cells as needed.\n",
        "\n",
        "def run_app(img_path):\n",
        "    ## handle cases for a human face, dog, and neither\n",
        "    if face_detector(img_path):\n",
        "      return predict_breed_transfer(img_path)\n",
        "    \n",
        "    elif dog_detector(img_path):\n",
        "      return predict_breed_transfer(img_path)\n",
        "    \n",
        "    else:\n",
        "      return 'Error'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4ofrSg4v2uI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id='step6'></a>\n",
        "## Step 6: Testing the Algorithm"
      ]
    },
    {
      "metadata": {
        "id": "qJdFK2wOv2uI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The output is around what I expected. It can be improved further:\n",
        "\n",
        "*   Accurcay can be further impoved. More epochs can push it beyond 90% level.\n",
        "*   Size of the model can be reduced by having the same model with fewer layers. (Densenet121 or Densenet161)\n",
        "*   Inception model can be used, instead of densenet. It may have higher performance. "
      ]
    },
    {
      "metadata": {
        "id": "fyC8eBqdIjA-",
        "colab_type": "code",
        "outputId": "c465ed06-b3a6-4f6e-f8d3-6119bcdd1a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "# download images\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/a/ae/Alia_Bhatt_2016.jpg -O alia.jpg\n",
        "!wget https://cdn0.wideopenpets.com/wp-content/uploads/2018/03/Akita-770x405.jpg -O dog.jpg\n",
        "!wget https://i1.wp.com/4f7bg01yl3z03jojs41hgo8k-wpengine.netdna-ssl.com/wp-content/uploads/2016/10/HF160920_Global_Blog_All_About_Apples_15_low.jpg?ssl=1 -O apple.jpg"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-01 17:12:19--  https://upload.wikimedia.org/wikipedia/commons/a/ae/Alia_Bhatt_2016.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153625 (150K) [image/jpeg]\n",
            "Saving to: ‘alia.jpg’\n",
            "\n",
            "\ralia.jpg              0%[                    ]       0  --.-KB/s               \ralia.jpg            100%[===================>] 150.02K   936KB/s    in 0.2s    \n",
            "\n",
            "2019-03-01 17:12:19 (936 KB/s) - ‘alia.jpg’ saved [153625/153625]\n",
            "\n",
            "--2019-03-01 17:12:22--  https://cdn0.wideopenpets.com/wp-content/uploads/2018/03/Akita-770x405.jpg\n",
            "Resolving cdn0.wideopenpets.com (cdn0.wideopenpets.com)... 104.25.232.5, 104.25.233.5, 2606:4700:20::6819:e905, ...\n",
            "Connecting to cdn0.wideopenpets.com (cdn0.wideopenpets.com)|104.25.232.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37648 (37K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg’\n",
            "\n",
            "dog.jpg             100%[===================>]  36.77K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-03-01 17:12:23 (50.1 MB/s) - ‘dog.jpg’ saved [37648/37648]\n",
            "\n",
            "--2019-03-01 17:12:26--  https://i1.wp.com/4f7bg01yl3z03jojs41hgo8k-wpengine.netdna-ssl.com/wp-content/uploads/2016/10/HF160920_Global_Blog_All_About_Apples_15_low.jpg?ssl=1\n",
            "Resolving i1.wp.com (i1.wp.com)... 192.0.77.2\n",
            "Connecting to i1.wp.com (i1.wp.com)|192.0.77.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1043569 (1019K) [image/jpeg]\n",
            "Saving to: ‘apple.jpg’\n",
            "\n",
            "apple.jpg           100%[===================>]   1019K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-03-01 17:12:26 (13.0 MB/s) - ‘apple.jpg’ saved [1043569/1043569]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XtQ6e7GOv2uJ",
        "colab_type": "code",
        "outputId": "e07f827c-8937-4924-eaff-4c9061217772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "## Execute your algorithm from Step 6 on\n",
        "## at least 6 images.\n",
        "## Feel free to use as many code cells as needed.\n",
        "\n",
        "## suggested code, below\n",
        "# 3 human and three dog images\n",
        "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
        "    print(run_app(file))\n",
        "\n",
        "# 1 human, dog, neither human nor dog    \n",
        "print(run_app('alia.jpg'))\n",
        "print(run_app('dog.jpg'))\n",
        "print(run_app('apple.jpg'))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "American staffordshire terrier\n",
            "Great dane\n",
            "Chinese shar-pei\n",
            "Boston terrier\n",
            "Boston terrier\n",
            "Boston terrier\n",
            "Greyhound\n",
            "Canaan dog\n",
            "Error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mL9OV08LOLxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}